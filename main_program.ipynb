{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2 \n",
    "import sys,os,shutil\n",
    "from p3_generatePathPoints import remove_dir,check_dir,generate_osm_routes_main, log_error\n",
    "from preprocess_csv_data import preprocess_data\n",
    "import pandas as pd\n",
    "\n",
    "import time\n",
    "from datetime import datetime\n",
    "from annomize import anonymize_column_values\n",
    "\n",
    "#config.py contains Variables that contains the user credentials to access Twitter API \n",
    "from config import connect_str,dbpassword,dbuser,host,database,shp_table_name,column_name,column_name_value\n",
    "\n",
    "from config import TEMP_DIR,OUTPUT_DIR,INPUT_DIR,ANONYMIZED_CSV_FILE,INPUT_SHP_FILE,PREPROCESSED_CSV_FILE,PREPROCESSED_CLIP_FILE, SAMPLING_PERCENT\n",
    "\n",
    "from config import PROBE_TABLE_NAME,CLIPPED_PROBE_TABLE, GPX_DIR, CSV_DIR, RES_CSV_DIR, RAW_CSV_FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################    \n",
    "def init_directory():\n",
    "    # remove old files\n",
    "    remove_dir(OUTPUT_DIR)\n",
    "    remove_dir(INPUT_DIR)\n",
    "    remove_dir(GPX_DIR)\n",
    "    remove_dir(CSV_DIR)\n",
    "    remove_dir(RES_CSV_DIR)\n",
    "\n",
    "    # create necessary directories\n",
    "    check_dir(INPUT_DIR)\n",
    "    check_dir(OUTPUT_DIR)\n",
    "    check_dir(TEMP_DIR)\n",
    "    check_dir(GPX_DIR)\n",
    "    check_dir(CSV_DIR)\n",
    "    check_dir(RES_CSV_DIR)\n",
    " \n",
    "\n",
    "def close_connection(connection):\n",
    "    \n",
    "    if connection is not None:\n",
    "        connection.close()\n",
    "        print('Connection closed.')\n",
    "\n",
    "\n",
    "def connect():\n",
    "    \"\"\" Connect to the PostgreSQL database server \"\"\"\n",
    "    conn = None\n",
    "    try:      \n",
    "        # connect to the PostgreSQL server\n",
    "        #print('\\nDatabase connected...')\n",
    "        conn = psycopg2.connect(connect_str)\n",
    "   \n",
    "    except (Exception, psycopg2.DatabaseError) as error:\n",
    "        print(error)\n",
    "   \n",
    "    return conn\n",
    "\n",
    "def clip_points_within_selected_region(clean_table_name):\n",
    "\t\n",
    "\tdrop_table(clean_table_name)# drop table if exists  \n",
    "\t\n",
    "\n",
    "\tprint (\"\\n Clipping Points within selected Region  \\n\\t Please wait...\")\n",
    "\t#sql = \" create table \"+ clean_table_name +\" AS\tSELECT o.*\tFROM \"+PROBE_TABLE_NAME+\" o ,\"+shp_table_name+\" a WHERE ST_DWithin(a.geom::geography, o.geom::geography, 0.01 ) and  a.\"+column_name+\"='\"+column_name_value+\"';\"\n",
    "\t\n",
    "\tsql = \"\tCREATE TABLE \"+ clean_table_name +\" AS\tSELECT o.*\tFROM \"+PROBE_TABLE_NAME+\" o ,\"+shp_table_name+\" a WHERE ST_DWithin(a.geom, o.geom, 0.01 ) AND  a.\"+column_name+\"='\"+column_name_value+\"';\"\n",
    "\t\n",
    " \n",
    "\t\n",
    "\tprint (sql)\n",
    "\t\n",
    "\tconn= connect()\n",
    "\tcur = conn.cursor()\n",
    "\tcur.execute(sql)  \n",
    "\tconn.commit()\t \n",
    "\tcur.close()\n",
    "\tclose_connection(conn)\n",
    "\t\n",
    "\t\n",
    "  \n",
    "def drop_table(table_name):     \n",
    "\tconn= connect()\n",
    "\tcur = conn.cursor()\n",
    "\tconn.autocommit = True\n",
    "\tdrop_sql = \"DROP TABLE IF EXISTS \"+ table_name\n",
    "\tprint (drop_sql)\n",
    "\tcur.execute(drop_sql) \t\n",
    "\tcur.close()\n",
    "\tclose_connection(conn)\n",
    "\t\n",
    "\ttime.sleep(2) # sleep for 2 seconds\n",
    "      \n",
    "      \n",
    "def create_db_table(table_name):\n",
    "\t#1. remove table if exists, 2. add csv to table, 3.create geom field\n",
    "\t\n",
    "\t\n",
    "\tdrop_table(table_name)# drop table if exists\n",
    "\t\n",
    "\tconn= connect()\n",
    "\tcur = conn.cursor()\n",
    "\t\t\n",
    "\tcreate_sql = \"CREATE TABLE \"+ table_name + \"\t(\\\n",
    "\t\t\tid integer,\\\n",
    "\t\t\tap_id text ,\\\n",
    "\t\t\ttimestamp timestamp without time zone,\\\n",
    "\t\t\tlatitude double precision,\\\n",
    "\t\t\tlongitude double precision,\\\n",
    "\t\t\tgeom geometry(Point,4326)\\\n",
    "\t\t)\"\n",
    "\t\t\n",
    "\tprint (create_sql)\n",
    "\tprint (\"_________________________________________________________\")\n",
    "\t\t\n",
    "\tcur.execute(create_sql) \n",
    "\tconn.commit()\n",
    "\t\n",
    "\tcur.close()\n",
    "\tclose_connection(conn)\n",
    "\t\n",
    "\t\n",
    "def create_geometry_from_latlon(table_name):\n",
    "\tconn= connect()\n",
    "\tcur = conn.cursor()\n",
    "\tupdate_sql = \"UPDATE \"+ table_name +\" SET geom = ST_SetSRID(ST_MakePoint(longitude, latitude), 4326);\"\n",
    "\t\n",
    "\tprint (update_sql)\n",
    "\tprint (\"_________________________________________________________\")\n",
    "\tcur.execute(update_sql)  # executemany\n",
    "\tconn.commit()\n",
    "\t\n",
    "\tcur.close()\n",
    "\tclose_connection(conn)\n",
    "\n",
    "\n",
    "\n",
    "def create_spatial_index(table_name):\n",
    "\tconn= connect()\n",
    "\tcur = conn.cursor() #\n",
    "\tconn.autocommit = True\n",
    "\tsql = \"CREATE INDEX ON \"+ table_name +\" USING GIST(geom);\"\n",
    "\t\n",
    "\tprint (sql)\n",
    "\tprint (\"_________________________________________________________\")\n",
    "\tcur.execute(sql)  # executemany\n",
    "\t#conn.commit()\n",
    "\t\n",
    "\tcur.close()\n",
    "\tclose_connection(conn)\n",
    "\n",
    "\n",
    "\n",
    "def vaccum_analyze_spatial_index(table_name):\n",
    "\tconn= connect()\n",
    "\tcur = conn.cursor() #\n",
    "\tconn.autocommit = True\n",
    "\tsql = \"VACUUM ANALYZE \"+ table_name +\";\"\n",
    "\t\n",
    "\tprint (sql)\n",
    "\tprint (\"_________________________________________________________\")\n",
    "\tcur.execute(sql)  # executemany\n",
    "\t#conn.commit()\n",
    "\t\n",
    "\tcur.close()\n",
    "\tclose_connection(conn)\n",
    "\n",
    "\n",
    "def transform_epsg(table_name, col = 'geom', geometry ='Point', epsg=4326):\n",
    "\tconn= connect()\n",
    "\tcur = conn.cursor() #\n",
    "\tconn.autocommit = True\n",
    "\tsql =  \"ALTER TABLE \"+ table_name +\" \\\n",
    "\t\t\tALTER COLUMN \"+col+\" \\\n",
    "\t\t\tTYPE Geometry(\"+geometry+\", \"+str(epsg)+\")  USING ST_Transform(geom, \"+str(epsg)+\");\"\n",
    "\t\n",
    "\tprint (sql)\n",
    "\tprint (\"_________________________________________________________\")\n",
    "\tcur.execute(sql)  # executemany\n",
    "\t#conn.commit()\n",
    "\t\n",
    "\tcur.close()\n",
    "\tclose_connection(conn)\n",
    "\n",
    "\n",
    "\n",
    "def clip_data_for_selected_region():\n",
    "\t#--- 2.import csv to PostGIS\t\n",
    "\tcreate_db_table(PROBE_TABLE_NAME)# create target table , drop existing table with same name\n",
    "\tcsv_2_psql(PREPROCESSED_CSV_FILE, PROBE_TABLE_NAME)\n",
    "\t\n",
    "\tcreate_geometry_from_latlon(PROBE_TABLE_NAME)\n",
    "\t\n",
    "\t### CREATE INDEX on Geometry column\t\n",
    "\tcreate_spatial_index(PROBE_TABLE_NAME)\n",
    "\tvaccum_analyze_spatial_index(PROBE_TABLE_NAME)\n",
    "\t\n",
    "\t\n",
    "\t## convert to planner projection ( for faster join operation)\n",
    "\ttransform_epsg(PROBE_TABLE_NAME, col = 'geom' , geometry= 'Point', epsg=3857)\n",
    "\t\n",
    "\ttransform_epsg(shp_table_name, col = 'geom', geometry= 'MultiPolygon', epsg=3857)\n",
    "\n",
    "\t### Create spatial index for shp table and probe table\n",
    "\tstart_time =  datetime.now()\n",
    "\tprint (start_time)\n",
    "\t\n",
    "\t#--- 3. Clip GPS points within original region\t\n",
    "\tclip_points_within_selected_region(CLIPPED_PROBE_TABLE) ### UNCOMMENT\n",
    "\t\n",
    "\tend_time =  datetime.now() \n",
    "\ttime_taken = (end_time - start_time).total_seconds()\n",
    "\t\n",
    "\tlog_error('clip_points_within_selected_region() time(sec) '+ str(time_taken), log_file = 'log_DatabaseTime.txt')\n",
    "\t\n",
    "\t\n",
    "\t#--- 4.  save clean_clipped data to csv\n",
    "\ttransform_epsg(PROBE_TABLE_NAME, col = 'geom' , geometry= 'Point', epsg=4326)\n",
    "\n",
    "\tpsql_2_csv(PREPROCESSED_CLIP_FILE, CLIPPED_PROBE_TABLE)\n",
    "\t\n",
    "\t\n",
    "def csv_2_psql(csv_file_name, table_name):\t\n",
    "\t\t\n",
    "\tconn = connect()\n",
    "\tcur = conn.cursor()\n",
    "\tconn.autocommit = True\n",
    "\tcsv_fr = open(csv_file_name, 'r') \n",
    "\tcols = csv_fr.readline().strip('\\n').split(',')\n",
    "\tcur.copy_from(csv_fr, table_name, sep=',', columns= cols)  \n",
    "\tcsv_fr.close()\n",
    "\tcur.close()\n",
    "\tclose_connection(conn)\n",
    "\tprint(\"Imported Data from \", csv_file_name, ' to ', table_name)\n",
    "\tprint (\"_________________________________________________________\")\n",
    "\t\n",
    "\t\n",
    "\n",
    "def psql_2_csv(csv_file_name, table_name):\n",
    "\t\n",
    "\tconn = connect()\n",
    "\tsql_query = \"SELECT *  FROM \"+ table_name\n",
    "\tdf_original = pd.read_sql_query(sql = sql_query, con = conn)\n",
    "\tclose_connection(conn)\n",
    "\tdf_original.to_csv(csv_file_name,index=False)\n",
    "\tprint(\"Preprocessed and CLipped File saved: \", csv_file_name)\n",
    "\tprint (\"_________________________________________________________\")\n",
    "\t\t\t\n",
    "\n",
    "\n",
    "def preprocessing_completed(preprocessed_file_name):\n",
    "\t\n",
    "\tif not os.path.isfile(preprocessed_file_name):\n",
    "\t\t\n",
    "\t\tprint(\"Please Complete Preprocessing FIRST !\")\n",
    "\t\t\n",
    "\t\treturn False\n",
    "\t\n",
    "\treturn True\n",
    "\t\n",
    "def generate_routes():\n",
    "\t\t\n",
    "\t#PREPROCESSED_CLIP_FILE\n",
    "\toutput_file =  OUTPUT_DIR +\"final_csv_4_mobmap_big.csv\"\n",
    "\tif shp_table_name == '':\n",
    "\t\tif preprocessing_completed(PREPROCESSED_CSV_FILE):\n",
    "\t\t\tgenerate_osm_routes_main(PREPROCESSED_CSV_FILE,output_file)\t\t\n",
    "\telse:\n",
    "\t\tif preprocessing_completed(PREPROCESSED_CLIP_FILE):\n",
    "\t\t\tgenerate_osm_routes_main(PREPROCESSED_CLIP_FILE,output_file)\n",
    "\t\t\n",
    "\tprint(\" Route Generation Complete. Check \" + OUTPUT_DIR )\n",
    "\n",
    "    ################\n",
    "\n",
    "def upload_shp_file2db(INPUT_SHP_FILE):\n",
    "\n",
    "\tif INPUT_SHP_FILE != '':\n",
    "\t\tdrop_table(shp_table_name)# drop table if exists  \n",
    "\t\tcreate_table_command = 'shp2pgsql -I -s 4326 '+INPUT_SHP_FILE+'  '+ shp_table_name +' | PGPASSWORD='+dbpassword+' psql -d '+database+' -h '+host+' -U '+dbuser+' '\n",
    "\t\tprint (create_table_command)\n",
    "\t\tos.system(create_table_command)\t\n",
    "\t\tprint(\"Shapefile imported to PostGIS \" ) \n",
    "        \n",
    "\telse:\n",
    "\t\tprint(\"Shapefile NOT provided -> ASSUMPTION: all input points are within the desired geographic boundary \" )        \n",
    "\n",
    "\n",
    "def preprocess_and_map_match_input():\n",
    "\t\n",
    "\tanonymize_column_values( 'ap_id', RAW_CSV_FILE, ANONYMIZED_CSV_FILE)\n",
    "\t#---1. preprocess : deduplicate rows, handle ( same ts, diff loc)\n",
    "\tpreprocess_data(SAMPLING_PERCENT, ANONYMIZED_CSV_FILE,  PREPROCESSED_CSV_FILE)\n",
    "\t\n",
    "\tif shp_table_name != '':\n",
    "\t\tclip_data_for_selected_region()\n",
    "\n",
    "\tprint( \" Preprocessing Complete\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RUN PROGRAM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### select input csv file  & preprocess (apply map-matching)  and generte route points from OSM ( pyroutelib3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3  csv prepared:  input/csv/\n",
      "\n",
      "completed:  java -jar matching-web/target/graphhopper-map-matching-web-1.0-SNAPSHOT.jar import map-data/nepal-latest.osm.pbf\n",
      "Current Working Directory  /home/bidur/GPSProbeGeneration/map-matching-master\n",
      "\n",
      "completed:  java -jar matching-web/target/graphhopper-map-matching-web-1.0-SNAPSHOT.jar match matching-web/src/test/resources/target/*.gpx\n",
      "convert_resgpx2csv output/res_csv/\n",
      "map-matching-master/matching-web/src/test/resources/target/*.res.gpx\n",
      "2388763304263 ,completed:  output/res_csv/2388763304263_res.csv\n",
      "2322542112705 ,completed:  output/res_csv/2322542112705_res.csv\n",
      "9659971790910 ,completed:  output/res_csv/9659971790910_res.csv\n",
      "./input/preprocessed.csv\n",
      "DROP TABLE IF EXISTS gps_probe\n",
      "Connection closed.\n",
      "CREATE TABLE gps_probe\t(\t\t\tid integer,\t\t\tap_id text ,\t\t\ttimestamp timestamp without time zone,\t\t\tlatitude double precision,\t\t\tlongitude double precision,\t\t\tgeom geometry(Point,4326)\t\t)\n",
      "_________________________________________________________\n",
      "Connection closed.\n",
      "Connection closed.\n",
      "Imported Data from  ./input/preprocessed.csv  to  gps_probe\n",
      "_________________________________________________________\n",
      "UPDATE gps_probe SET geom = ST_SetSRID(ST_MakePoint(longitude, latitude), 4326);\n",
      "_________________________________________________________\n",
      "Connection closed.\n",
      "CREATE INDEX ON gps_probe USING GIST(geom);\n",
      "_________________________________________________________\n",
      "Connection closed.\n",
      "VACUUM ANALYZE gps_probe;\n",
      "_________________________________________________________\n",
      "Connection closed.\n",
      "ALTER TABLE gps_probe \t\t\tALTER COLUMN geom \t\t\tTYPE Geometry(Point, 3857)  USING ST_Transform(geom, 3857);\n",
      "_________________________________________________________\n",
      "Connection closed.\n",
      "ALTER TABLE gadm36_NPL_2 \t\t\tALTER COLUMN geom \t\t\tTYPE Geometry(MultiPolygon, 3857)  USING ST_Transform(geom, 3857);\n",
      "_________________________________________________________\n",
      "Connection closed.\n",
      "2020-10-07 11:48:57.600338\n",
      "DROP TABLE IF EXISTS gps_probe_clip\n",
      "Connection closed.\n",
      "\n",
      " Clipping Points within selected Region  \n",
      "\t Please wait...\n",
      "\tCREATE TABLE gps_probe_clip AS\tSELECT o.*\tFROM gps_probe o ,gadm36_NPL_2 a WHERE ST_DWithin(a.geom, o.geom, 0.01 ) AND  a.NAME_2='Bagmati';\n",
      "Connection closed.\n",
      "ALTER TABLE gps_probe \t\t\tALTER COLUMN geom \t\t\tTYPE Geometry(Point, 4326)  USING ST_Transform(geom, 4326);\n",
      "_________________________________________________________\n",
      "Connection closed.\n",
      "Connection closed.\n",
      "Preprocessed and CLipped File saved:  ./input/preprocessed_clipped.csv\n",
      "_________________________________________________________\n",
      " Preprocessing Complete\n"
     ]
    }
   ],
   "source": [
    "# initialize directories\n",
    "init_directory()\n",
    "\n",
    "#1. (OPTIONAL) upload shapefile  of target region ( if clipping of input data needed to avoid out of boundary input points )\n",
    "#upload_shp_file2db(INPUT_SHP_FILE) # comment this line if .shp file is already uploaded to database\n",
    "\n",
    "# 2. select input csv file  & preprocess\n",
    "preprocess_and_map_match_input()\n",
    "# The output/ directory will contain road aligned routes ( generated via graphhopper). This can be used for MopMap visualization\n",
    "\n",
    "# 3. (OPTIONAL) generate MORE route points via online query with OpenStreetMap  via pyroutelib3\n",
    "#generate_routes()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
